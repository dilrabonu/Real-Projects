{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMykIAI/ZvgKGrbBveVRg8r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dilrabonu/Real-Projects/blob/main/Dilrabo_Stream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oom0HmlfacJq",
        "outputId": "a4db4846-9b3a-439b-8527-c0f633219988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"RestaurantAnalysis\").getOrCreate()\n",
        "print(\"✅ Spark Session Started!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og3MtKlCavTC",
        "outputId": "0ca52a13-04c1-4fcf-e83b-823f0a5a8ba4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Spark Session Started!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgJ9OO9axbR",
        "outputId": "a04db80e-6eb1-4b9a-c0c1-3145a059add7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!file /content/Spark_Streaming--Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75q-2Y4aa4Tx",
        "outputId": "ecf58f2e-94e2-432e-cfa8-b359c7167c01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Spark_Streaming--Dataset.zip: Zip archive data, at least v1.0 to extract, compression method=store\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/Spark_Streaming--Dataset.zip\"\n",
        "extract_path = \"/content/\"\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"✅ Extraction Successful!\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"❌ The file is not a valid ZIP archive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRw4LoNxa93c",
        "outputId": "137bbc9a-5112-42d3-c8be-b91dc44e69dc"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction Successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Define paths\n",
        "files_to_extract = [\"/content/weather.zip\"]\n",
        "extract_path = \"/content/\"\n",
        "\n",
        "# Extract each file\n",
        "for file in files_to_extract:\n",
        "    try:\n",
        "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_path)\n",
        "        print(f\"✅ Successfully extracted {file}!\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"❌ Failed to extract {file}: Not a valid ZIP archive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R-bihVLbCzZ",
        "outputId": "3f363656-8301-4777-885b-c04be16746d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully extracted /content/weather.zip!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Define the zip file and extraction path\n",
        "zip_path = \"/content/receipt_restaurants.zip\"\n",
        "extract_path = \"/content/receipt_restaurants\"\n",
        "\n",
        "# Extract\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"✅ Successfully extracted receipt_restaurants.zip!\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"❌ The file is not a valid ZIP archive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyW-sjrbbLN6",
        "outputId": "eec74d6b-6627-4de1-ef36-ec06f2267058"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully extracted receipt_restaurants.zip!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2DRE-3KbmZC",
        "outputId": "a076bea2-1a67-4ace-ebdd-72328533e0a7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.3.2-bin-hadoop3.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"StreamingPractice\").getOrCreate()\n",
        "print(\"✅ Spark Session started\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P87i6P9ydLdw",
        "outputId": "07815292-e243-4e94-8ccb-7bd77a17a51f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Spark Session started\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2022_df = spark.read.option(\"header\", True).csv(\"/content/receipt_restaurants/part-*.csv\")\n",
        "receipt_2022_df.printSchema()\n",
        "receipt_2022_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws1nPqDSdUcx",
        "outputId": "784a3661-093e-41bf-cba2-47106d10bd32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- franchise_id: string (nullable = true)\n",
            " |-- franchise_name: string (nullable = true)\n",
            " |-- restaurant_franchise_id: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- lng: string (nullable = true)\n",
            " |-- receipt_id: string (nullable = true)\n",
            " |-- total_cost: string (nullable = true)\n",
            " |-- discount: string (nullable = true)\n",
            " |-- date_time: string (nullable = true)\n",
            "\n",
            "+------------+------------+-----------------+-----------------------+-------+---------+------+--------+------------------------------------+----------+--------+------------------------+\n",
            "|id          |franchise_id|franchise_name   |restaurant_franchise_id|country|city     |lat   |lng     |receipt_id                          |total_cost|discount|date_time               |\n",
            "+------------+------------+-----------------+-----------------------+-------+---------+------+--------+------------------------------------+----------+--------+------------------------+\n",
            "|188978561075|52          |The Red Door     |5034                   |AT     |Vienna   |48.215|16.376  |56df62bf-f7e7-47ff-8800-475bf46262cf|17.40     |0.15    |2022-09-05T17:32:50.000Z|\n",
            "|214748364857|58          |A Tasty Bite     |23242                  |FR     |Paris    |48.866|2.332   |f3ed7e84-f3c7-46e7-b855-f6def62911bb|17.12     |0.0     |2021-10-01T18:53:23.000Z|\n",
            "|266287972391|40          |Crimson Cafe     |70700                  |IT     |Milan    |45.473|9.191   |4cbfe14a-77ab-489e-aeb8-192931ad493a|13.90     |0.0     |2022-09-07T07:02:40.000Z|\n",
            "|17179869216 |33          |The Blue Elephant|66775                  |US     |Hill City|43.959|-103.737|397c3559-92fc-4f4d-9bf7-3ad47cb51620|20.78     |0.15    |2021-10-11T19:19:32.000Z|\n",
            "|25769803801 |26          |The Silver Spoon |95123                  |ES     |Barcelona|41.401|2.209   |10ef1be3-83d3-47db-a7d0-de7d71924f91|10.84     |0.1     |2021-10-04T09:57:45.000Z|\n",
            "+------------+------------+-----------------+-----------------------+-------+---------+------+--------+------------------------------------+----------+--------+------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = spark.read.option(\"header\", True).csv(\"/content/weather/part-*.csv\")\n",
        "weather_df.printSchema()\n",
        "weather_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WEOKiTpdf3y",
        "outputId": "aad65e56-0266-4f78-e668-a6e733cc2bce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- lng: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- avg_tmpr_c: string (nullable = true)\n",
            " |-- wthr_date: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n",
            "+------+------+----------+----------+------+-------+\n",
            "|lng   |lat   |avg_tmpr_c|wthr_date |city  |country|\n",
            "+------+------+----------+----------+------+-------+\n",
            "|2.326 |48.847|7.01      |2021-10-22|Paris |FR     |\n",
            "|2.352 |48.864|18.75     |2022-09-28|Paris |FR     |\n",
            "|2.328 |48.871|8.08      |2021-10-12|Paris |FR     |\n",
            "|-0.152|51.506|11.93     |2021-10-15|London|GB     |\n",
            "|2.307 |48.855|11.12     |2021-10-02|Paris |FR     |\n",
            "+------+------+----------+----------+------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, round, to_date\n",
        "\n",
        "\n",
        "receipt_2022_df = receipt_2022_df.withColumn(\"lat_round\", round(col(\"lat\").cast(\"double\"), 2)) \\\n",
        "                                 .withColumn(\"lng_round\", round(col(\"lng\").cast(\"double\"), 2)) \\\n",
        "                                 .withColumn(\"visit_date\", to_date(col(\"date_time\")))"
      ],
      "metadata": {
        "id": "rJtqhvzgeJG6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = weather_df.withColumn(\"lat_round\", round(col(\"lat\").cast(\"double\"), 2)) \\\n",
        "                       .withColumn(\"lng_round\", round(col(\"lng\").cast(\"double\"), 2)) \\\n",
        "                       .withColumn(\"avg_tmpr_c\", col(\"avg_tmpr_c\").cast(\"double\")) \\\n",
        "                       .withColumn(\"wthr_date\", to_date(\"wthr_date\"))"
      ],
      "metadata": {
        "id": "X-6-HhY0ebLm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "receipt_2022_alias = receipt_2022_df.alias(\"r\")\n",
        "weather_alias = weather_df.alias(\"w\")\n",
        "\n",
        "enriched_df = receipt_2022_alias.join(\n",
        "    weather_alias,\n",
        "    (col(\"r.lat_round\") == col(\"w.lat_round\")) &\n",
        "    (col(\"r.lng_round\") == col(\"w.lng_round\")) &\n",
        "    (col(\"r.visit_date\") == col(\"w.wthr_date\")),\n",
        "    how=\"left\"\n",
        ")\n",
        "\n",
        "\n",
        "enriched_df.select(\n",
        "    col(\"r.receipt_id\"),\n",
        "    col(\"r.visit_date\"),\n",
        "    col(\"w.avg_tmpr_c\"),\n",
        "    col(\"w.city\").alias(\"weather_city\"),\n",
        "    col(\"r.city\").alias(\"receipt_city\")\n",
        ").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55_mKxomeeQR",
        "outputId": "424bfb4b-d4ac-483a-e0be-8dbca5fffff3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------+----------+----------+------------+------------+\n",
            "|receipt_id                          |visit_date|avg_tmpr_c|weather_city|receipt_city|\n",
            "+------------------------------------+----------+----------+------------+------------+\n",
            "|56df62bf-f7e7-47ff-8800-475bf46262cf|2022-09-05|NULL      |NULL        |Vienna      |\n",
            "|f3ed7e84-f3c7-46e7-b855-f6def62911bb|2021-10-01|NULL      |NULL        |Paris       |\n",
            "|4cbfe14a-77ab-489e-aeb8-192931ad493a|2022-09-07|NULL      |NULL        |Milan       |\n",
            "|397c3559-92fc-4f4d-9bf7-3ad47cb51620|2021-10-11|NULL      |NULL        |Hill City   |\n",
            "|10ef1be3-83d3-47db-a7d0-de7d71924f91|2021-10-04|NULL      |NULL        |Barcelona   |\n",
            "+------------------------------------+----------+----------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2022_df.select(\"lat\", \"lng\", \"lat_round\", \"lng_round\", \"visit_date\").show(5)\n",
        "weather_df.select(\"lat\", \"lng\", \"lat_round\", \"lng_round\", \"wthr_date\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5P6qbxCekwq",
        "outputId": "a19628ce-b02c-4e62-ad6a-f604d16898a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+---------+---------+----------+\n",
            "|   lat|     lng|lat_round|lng_round|visit_date|\n",
            "+------+--------+---------+---------+----------+\n",
            "|48.215|  16.376|    48.22|    16.38|2022-09-05|\n",
            "|48.866|   2.332|    48.87|     2.33|2021-10-01|\n",
            "|45.473|   9.191|    45.47|     9.19|2022-09-07|\n",
            "|43.959|-103.737|    43.96|  -103.74|2021-10-11|\n",
            "|41.401|   2.209|     41.4|     2.21|2021-10-04|\n",
            "+------+--------+---------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+------+------+---------+---------+----------+\n",
            "|   lat|   lng|lat_round|lng_round| wthr_date|\n",
            "+------+------+---------+---------+----------+\n",
            "|48.847| 2.326|    48.85|     2.33|2021-10-22|\n",
            "|48.864| 2.352|    48.86|     2.35|2022-09-28|\n",
            "|48.871| 2.328|    48.87|     2.33|2021-10-12|\n",
            "|51.506|-0.152|    51.51|    -0.15|2021-10-15|\n",
            "|48.855| 2.307|    48.86|     2.31|2021-10-02|\n",
            "+------+------+---------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count\n",
        "\n",
        "\n",
        "test_join = receipt_2022_alias.join(\n",
        "    weather_alias,\n",
        "    (col(\"r.lat_round\") == col(\"w.lat_round\")) &\n",
        "    (col(\"r.lng_round\") == col(\"w.lng_round\")) &\n",
        "    (col(\"r.visit_date\") == col(\"w.wthr_date\")),\n",
        "    how=\"inner\"\n",
        ")\n",
        "\n",
        "test_join.select(\"r.receipt_id\").agg(count(\"*\").alias(\"matching_records\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFA3tBWLfXXn",
        "outputId": "6bcb1db9-5f15-4113-c913-6654da251abc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|matching_records|\n",
            "+----------------+\n",
            "|          531213|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = enriched_df.filter(col(\"avg_tmpr_c\") > 0)\n",
        "filtered_df.select(\"receipt_id\", \"visit_date\", \"avg_tmpr_c\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEc1RizVfdj8",
        "outputId": "0d72539a-9eb8-4da1-c9b8-4f02eb4db021"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------+----------+----------+\n",
            "|receipt_id                          |visit_date|avg_tmpr_c|\n",
            "+------------------------------------+----------+----------+\n",
            "|885ffe85-3320-49a5-bc91-8f8ed227af5a|2021-10-11|10.81     |\n",
            "|7e4432fc-0649-4eab-883c-e3e975501413|2022-09-01|30.01     |\n",
            "|d7da2e39-1c0c-4f11-8826-d174abc97e40|2022-08-17|15.91     |\n",
            "|d7da2e39-1c0c-4f11-8826-d174abc97e40|2022-08-17|16.44     |\n",
            "|d7da2e39-1c0c-4f11-8826-d174abc97e40|2022-08-17|16.03     |\n",
            "+------------------------------------+----------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "filtered_df = filtered_df.withColumn(\n",
        "    \"original_total_cost\",\n",
        "    col(\"r.total_cost\").cast(\"double\") + col(\"r.discount\").cast(\"double\")\n",
        ")\n",
        "\n",
        "filtered_df.select(\"receipt_id\", \"total_cost\", \"discount\", \"original_total_cost\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKZOwhVIftCV",
        "outputId": "134f856f-b008-4a96-e7ef-78c688dbfb92"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------+-------------------+\n",
            "|          receipt_id|total_cost|discount|original_total_cost|\n",
            "+--------------------+----------+--------+-------------------+\n",
            "|885ffe85-3320-49a...|     15.65|     0.0|              15.65|\n",
            "|7e4432fc-0649-4ea...|     27.93|     0.0|              27.93|\n",
            "|d7da2e39-1c0c-4f1...|     21.84|     0.0|              21.84|\n",
            "|d7da2e39-1c0c-4f1...|     21.84|     0.0|              21.84|\n",
            "|d7da2e39-1c0c-4f1...|     21.84|     0.0|              21.84|\n",
            "+--------------------+----------+--------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "col(\"r.items\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkYgMwPXgw5X",
        "outputId": "c6ca7477-6d79-4c15-a2d2-6eee78e9208e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'r.items'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONzYNlB5f5nH",
        "outputId": "822553f8-c100-4441-8f93-a68e4e4b34d4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- franchise_id: string (nullable = true)\n",
            " |-- franchise_name: string (nullable = true)\n",
            " |-- restaurant_franchise_id: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- lng: string (nullable = true)\n",
            " |-- receipt_id: string (nullable = true)\n",
            " |-- total_cost: string (nullable = true)\n",
            " |-- discount: string (nullable = true)\n",
            " |-- date_time: string (nullable = true)\n",
            " |-- lat_round: double (nullable = true)\n",
            " |-- lng_round: double (nullable = true)\n",
            " |-- visit_date: date (nullable = true)\n",
            " |-- lng: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- avg_tmpr_c: double (nullable = true)\n",
            " |-- wthr_date: date (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- lat_round: double (nullable = true)\n",
            " |-- lng_round: double (nullable = true)\n",
            " |-- original_total_cost: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2022_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmxPUsddgWa2",
        "outputId": "ea90f797-b37c-4a6f-cfd3-0fa23699e008"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- franchise_id: string (nullable = true)\n",
            " |-- franchise_name: string (nullable = true)\n",
            " |-- restaurant_franchise_id: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- lng: string (nullable = true)\n",
            " |-- receipt_id: string (nullable = true)\n",
            " |-- total_cost: string (nullable = true)\n",
            " |-- discount: string (nullable = true)\n",
            " |-- date_time: string (nullable = true)\n",
            " |-- lat_round: double (nullable = true)\n",
            " |-- lng_round: double (nullable = true)\n",
            " |-- visit_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check available columns in one file\n",
        "spark.read.option(\"header\", True).csv(\"/content/receipt_restaurants/part-00000*.csv\").printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tOT6DIpiPcH",
        "outputId": "e0db4e48-c8d8-492a-8b6a-23cd12cd5b64"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- franchise_id: string (nullable = true)\n",
            " |-- franchise_name: string (nullable = true)\n",
            " |-- restaurant_franchise_id: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- lng: string (nullable = true)\n",
            " |-- receipt_id: string (nullable = true)\n",
            " |-- total_cost: string (nullable = true)\n",
            " |-- discount: string (nullable = true)\n",
            " |-- date_time: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "# Add simulated 'items' column for task continuation\n",
        "receipt_2022_df = receipt_2022_df.withColumn(\"items\", (rand() * 15).cast(\"int\"))\n",
        "\n",
        "# Rebuild alias and enriched_df if needed\n",
        "receipt_2022_df = receipt_2022_df.withColumn(\"lat_round\", round(col(\"lat\").cast(\"double\"), 2)) \\\n",
        "                                 .withColumn(\"lng_round\", round(col(\"lng\").cast(\"double\"), 2)) \\\n",
        "                                 .withColumn(\"visit_date\", to_date(\"date_time\"))\n",
        "\n",
        "receipt_2022_alias = receipt_2022_df.alias(\"r\")\n",
        "weather_alias = weather_df.alias(\"w\")\n",
        "\n",
        "enriched_df = receipt_2022_alias.join(\n",
        "    weather_alias,\n",
        "    (col(\"r.lat_round\") == col(\"w.lat_round\")) &\n",
        "    (col(\"r.lng_round\") == col(\"w.lng_round\")) &\n",
        "    (col(\"r.visit_date\") == col(\"w.wthr_date\")),\n",
        "    how=\"left\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "y6j4zHsAiax1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select enriched features (include the new 'items')\n",
        "filtered_df = enriched_df.select(\n",
        "    col(\"r.receipt_id\"),\n",
        "    col(\"r.visit_date\"),\n",
        "    col(\"r.total_cost\"),\n",
        "    col(\"r.discount\"),\n",
        "    col(\"r.items\"),\n",
        "    col(\"w.avg_tmpr_c\"),\n",
        "    col(\"r.restaurant_franchise_id\")\n",
        ").filter(col(\"avg_tmpr_c\") > 0)\n"
      ],
      "metadata": {
        "id": "8hVlRuA2j2JY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Derive item_count & order_type\n",
        "filtered_df = filtered_df.withColumn(\"item_count\", col(\"items\").cast(\"int\"))\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "filtered_df = filtered_df.withColumn(\n",
        "    \"order_type\",\n",
        "    when(col(\"item_count\").isNull() | (col(\"item_count\") <= 0), \"Erroneous data\")\n",
        "    .when(col(\"item_count\") <= 1, \"Tiny order\")\n",
        "    .when(col(\"item_count\") <= 3, \"Small order\")\n",
        "    .when(col(\"item_count\") <= 10, \"Medium order\")\n",
        "    .otherwise(\"Large order\")\n",
        ")\n",
        "\n",
        "filtered_df.select(\"receipt_id\", \"item_count\", \"order_type\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvim729Lj38q",
        "outputId": "386ba574-0e2c-4c13-d12b-027f0ba3cd4a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+\n",
            "|          receipt_id|item_count|    order_type|\n",
            "+--------------------+----------+--------------+\n",
            "|885ffe85-3320-49a...|         3|   Small order|\n",
            "|7e4432fc-0649-4ea...|         3|   Small order|\n",
            "|d7da2e39-1c0c-4f1...|         0|Erroneous data|\n",
            "|d7da2e39-1c0c-4f1...|         0|Erroneous data|\n",
            "|d7da2e39-1c0c-4f1...|         0|Erroneous data|\n",
            "+--------------------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, col\n",
        "\n",
        "\n",
        "grouped_df = filtered_df.groupBy(\"restaurant_franchise_id\", \"order_type\").agg(\n",
        "    count(\"*\").alias(\"order_count\")\n",
        ")\n",
        "\n",
        "\n",
        "pivoted_df = grouped_df.groupBy(\"restaurant_franchise_id\").pivot(\"order_type\").sum(\"order_count\")\n",
        "\n",
        "\n",
        "final_state_df = pivoted_df \\\n",
        "    .withColumnRenamed(\"Erroneous data\", \"erroneous_data_cnt\") \\\n",
        "    .withColumnRenamed(\"Tiny order\", \"tiny_cnt\") \\\n",
        "    .withColumnRenamed(\"Small order\", \"small_cnt\") \\\n",
        "    .withColumnRenamed(\"Medium order\", \"medium_cnt\") \\\n",
        "    .withColumnRenamed(\"Large order\", \"large_cnt\")\n"
      ],
      "metadata": {
        "id": "Fuq4AV6kj5qB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_state_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAO_MqhqkKRh",
        "outputId": "6f0edf9a-3dae-414c-a6cc-ca1b7a6618c0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+------------------+---------+----------+---------+--------+\n",
            "|restaurant_franchise_id|erroneous_data_cnt|large_cnt|medium_cnt|small_cnt|tiny_cnt|\n",
            "+-----------------------+------------------+---------+----------+---------+--------+\n",
            "|22875                  |608               |3131     |5911      |1310     |795     |\n",
            "|76199                  |910               |3558     |5789      |1616     |809     |\n",
            "|23242                  |1728              |7686     |12703     |3664     |1731    |\n",
            "|80392                  |961               |4403     |7756      |2216     |971     |\n",
            "|48721                  |570               |2489     |4363      |1207     |611     |\n",
            "+-----------------------+------------------+---------+----------+---------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "final_state_df = final_state_df.fillna(0)\n",
        "\n",
        "final_state_df = final_state_df.withColumn(\n",
        "    \"most_popular_order_type\",\n",
        "    when(\n",
        "        (col(\"large_cnt\") >= col(\"medium_cnt\")) &\n",
        "        (col(\"large_cnt\") >= col(\"small_cnt\")) &\n",
        "        (col(\"large_cnt\") >= col(\"tiny_cnt\")) &\n",
        "        (col(\"large_cnt\") >= col(\"erroneous_data_cnt\")), \"Large order\"\n",
        "    ).when(\n",
        "        (col(\"medium_cnt\") >= col(\"small_cnt\")) &\n",
        "        (col(\"medium_cnt\") >= col(\"tiny_cnt\")) &\n",
        "        (col(\"medium_cnt\") >= col(\"erroneous_data_cnt\")), \"Medium order\"\n",
        "    ).when(\n",
        "        (col(\"small_cnt\") >= col(\"tiny_cnt\")) &\n",
        "        (col(\"small_cnt\") >= col(\"erroneous_data_cnt\")), \"Small order\"\n",
        "    ).when(\n",
        "        (col(\"tiny_cnt\") >= col(\"erroneous_data_cnt\")), \"Tiny order\"\n",
        "    ).otherwise(\"Erroneous data\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "BslJJ35wkaMa"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_state_df.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBOPVWhGkhgR",
        "outputId": "63fe1b0f-c5ad-425d-c3d6-9c0f0bf75be5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+------------------+---------+----------+---------+--------+-----------------------+\n",
            "|restaurant_franchise_id|erroneous_data_cnt|large_cnt|medium_cnt|small_cnt|tiny_cnt|most_popular_order_type|\n",
            "+-----------------------+------------------+---------+----------+---------+--------+-----------------------+\n",
            "|22875                  |608               |3131     |5911      |1310     |795     |Medium order           |\n",
            "|76199                  |910               |3558     |5789      |1616     |809     |Medium order           |\n",
            "|23242                  |1728              |7686     |12703     |3664     |1731    |Medium order           |\n",
            "|80392                  |961               |4403     |7756      |2216     |971     |Medium order           |\n",
            "|48721                  |570               |2489     |4363      |1207     |611     |Medium order           |\n",
            "+-----------------------+------------------+---------+----------+---------+--------+-----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_state_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"/content/output/initial_state\")\n"
      ],
      "metadata": {
        "id": "1LfRvbG3lDkf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read 2021 Receipt Data**"
      ],
      "metadata": {
        "id": "aIC3uQeGlpON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2021_df = spark.read.option(\"header\", True).csv(\"/content/receipt_restaurants/part-0000*.csv\")\n",
        "\n",
        "# Cast and enrich as done for 2022\n",
        "from pyspark.sql.functions import to_date, col, round\n",
        "\n",
        "receipt_2021_df = receipt_2021_df \\\n",
        "    .withColumn(\"lat_round\", round(col(\"lat\").cast(\"double\"), 2)) \\\n",
        "    .withColumn(\"lng_round\", round(col(\"lng\").cast(\"double\"), 2)) \\\n",
        "    .withColumn(\"visit_date\", to_date(\"date_time\"))\n"
      ],
      "metadata": {
        "id": "VCkgg1jslXCZ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = spark.read.option(\"header\", True).csv(\"/content/weather/part-*.csv\")\n",
        "\n",
        "weather_df = weather_df \\\n",
        "    .withColumn(\"lat_round\", round(col(\"lat\").cast(\"double\"), 2)) \\\n",
        "    .withColumn(\"lng_round\", round(col(\"lng\").cast(\"double\"), 2)) \\\n",
        "    .withColumn(\"wthr_date\", to_date(\"wthr_date\")) \\\n",
        "    .withColumn(\"avg_tmpr_c\", col(\"avg_tmpr_c\").cast(\"double\"))\n"
      ],
      "metadata": {
        "id": "NWV1Xo7klomO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH-sgahtlxnP",
        "outputId": "8bef0cb0-7b8b-4ac8-d4f2-0d784be9d039"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+----------+----------+------+-------+---------+---------+\n",
            "|lng   |lat   |avg_tmpr_c|wthr_date |city  |country|lat_round|lng_round|\n",
            "+------+------+----------+----------+------+-------+---------+---------+\n",
            "|2.326 |48.847|7.01      |2021-10-22|Paris |FR     |48.85    |2.33     |\n",
            "|2.352 |48.864|18.75     |2022-09-28|Paris |FR     |48.86    |2.35     |\n",
            "|2.328 |48.871|8.08      |2021-10-12|Paris |FR     |48.87    |2.33     |\n",
            "|-0.152|51.506|11.93     |2021-10-15|London|GB     |51.51    |-0.15    |\n",
            "|2.307 |48.855|11.12     |2021-10-02|Paris |FR     |48.86    |2.31     |\n",
            "+------+------+----------+----------+------+-------+---------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2021_alias = receipt_2021_df.alias(\"r\")\n",
        "weather_alias = weather_df.alias(\"w\")\n",
        "\n",
        "enriched_df = receipt_2021_alias.join(\n",
        "    weather_alias,\n",
        "    (col(\"r.lat_round\") == col(\"w.lat_round\")) &\n",
        "    (col(\"r.lng_round\") == col(\"w.lng_round\")) &\n",
        "    (col(\"r.visit_date\") == col(\"w.wthr_date\")),\n",
        "    how=\"left\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "pjRowI_2l466"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InYsrsmtl7QH",
        "outputId": "96c4bc29-7499-45a4-8683-bff4d37bc7b7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+-----------------+-----------------------+-------+---------+------+--------+------------------------------------+----------+--------+------------------------+---------+---------+----------+----+----+----------+---------+----+-------+---------+---------+\n",
            "|id          |franchise_id|franchise_name   |restaurant_franchise_id|country|city     |lat   |lng     |receipt_id                          |total_cost|discount|date_time               |lat_round|lng_round|visit_date|lng |lat |avg_tmpr_c|wthr_date|city|country|lat_round|lng_round|\n",
            "+------------+------------+-----------------+-----------------------+-------+---------+------+--------+------------------------------------+----------+--------+------------------------+---------+---------+----------+----+----+----------+---------+----+-------+---------+---------+\n",
            "|188978561075|52          |The Red Door     |5034                   |AT     |Vienna   |48.215|16.376  |56df62bf-f7e7-47ff-8800-475bf46262cf|17.40     |0.15    |2022-09-05T17:32:50.000Z|48.22    |16.38    |2022-09-05|NULL|NULL|NULL      |NULL     |NULL|NULL   |NULL     |NULL     |\n",
            "|214748364857|58          |A Tasty Bite     |23242                  |FR     |Paris    |48.866|2.332   |f3ed7e84-f3c7-46e7-b855-f6def62911bb|17.12     |0.0     |2021-10-01T18:53:23.000Z|48.87    |2.33     |2021-10-01|NULL|NULL|NULL      |NULL     |NULL|NULL   |NULL     |NULL     |\n",
            "|266287972391|40          |Crimson Cafe     |70700                  |IT     |Milan    |45.473|9.191   |4cbfe14a-77ab-489e-aeb8-192931ad493a|13.90     |0.0     |2022-09-07T07:02:40.000Z|45.47    |9.19     |2022-09-07|NULL|NULL|NULL      |NULL     |NULL|NULL   |NULL     |NULL     |\n",
            "|17179869216 |33          |The Blue Elephant|66775                  |US     |Hill City|43.959|-103.737|397c3559-92fc-4f4d-9bf7-3ad47cb51620|20.78     |0.15    |2021-10-11T19:19:32.000Z|43.96    |-103.74  |2021-10-11|NULL|NULL|NULL      |NULL     |NULL|NULL   |NULL     |NULL     |\n",
            "|25769803801 |26          |The Silver Spoon |95123                  |ES     |Barcelona|41.401|2.209   |10ef1be3-83d3-47db-a7d0-de7d71924f91|10.84     |0.1     |2021-10-04T09:57:45.000Z|41.4     |2.21     |2021-10-04|NULL|NULL|NULL      |NULL     |NULL|NULL   |NULL     |NULL     |\n",
            "+------------+------------+-----------------+-----------------------+-------+---------+------+--------+------------------------------------+----------+--------+------------------------+---------+---------+----------+----+----+----------+---------+----+-------+---------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = enriched_df.filter(col(\"avg_tmpr_c\") > 0)\n"
      ],
      "metadata": {
        "id": "xG1If0ZemBZ1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "filtered_df = filtered_df.withColumn(\n",
        "    \"original_total_cost\",\n",
        "    col(\"total_cost\").cast(\"double\") + col(\"discount\").cast(\"double\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "Yz1xtKsRmNn9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df.show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxFsHksumQ5K",
        "outputId": "2ed2f38a-a0be-4d60-987d-d099ab0ea5e0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+------------------+-----------------------+-------+-----------+------+--------+------------------------------------+----------+--------+------------------------+---------+---------+----------+--------+------+----------+----------+-----------+-------+---------+---------+-------------------+\n",
            "|id          |franchise_id|franchise_name    |restaurant_franchise_id|country|city       |lat   |lng     |receipt_id                          |total_cost|discount|date_time               |lat_round|lng_round|visit_date|lng     |lat   |avg_tmpr_c|wthr_date |city       |country|lat_round|lng_round|original_total_cost|\n",
            "+------------+------------+------------------+-----------------------+-------+-----------+------+--------+------------------------------------+----------+--------+------------------------+---------+---------+----------+--------+------+----------+----------+-----------+-------+---------+---------+-------------------+\n",
            "|77309411383 |56          |The Waffle House  |63415                  |GB     |London     |51.461|-0.276  |885ffe85-3320-49a5-bc91-8f8ed227af5a|15.65     |0.0     |2021-10-11T03:45:43.000Z|51.46    |-0.28    |2021-10-11|-0.276  |51.461|10.81     |2021-10-11|London     |GB     |51.46    |-0.28    |15.65              |\n",
            "|103079215117|14          |The Gourmet Garden|1670                   |US     |Victorville|34.507|-117.326|7e4432fc-0649-4eab-883c-e3e975501413|27.93     |0.0     |2022-09-01T08:29:03.000Z|34.51    |-117.33  |2022-09-01|-117.326|34.507|30.01     |2022-09-01|Victorville|US     |34.51    |-117.33  |27.93              |\n",
            "|120259084341|54          |The Spice House   |40542                  |GB     |London     |51.502|-0.119  |d7da2e39-1c0c-4f11-8826-d174abc97e40|21.84     |0.0     |2022-08-17T15:04:06.000Z|51.5     |-0.12    |2022-08-17|-0.117  |51.501|15.91     |2022-08-17|London     |GB     |51.5     |-0.12    |21.84              |\n",
            "|120259084341|54          |The Spice House   |40542                  |GB     |London     |51.502|-0.119  |d7da2e39-1c0c-4f11-8826-d174abc97e40|21.84     |0.0     |2022-08-17T15:04:06.000Z|51.5     |-0.12    |2022-08-17|-0.116  |51.501|16.44     |2022-08-17|London     |GB     |51.5     |-0.12    |21.84              |\n",
            "|120259084341|54          |The Spice House   |40542                  |GB     |London     |51.502|-0.119  |d7da2e39-1c0c-4f11-8826-d174abc97e40|21.84     |0.0     |2022-08-17T15:04:06.000Z|51.5     |-0.12    |2022-08-17|-0.119  |51.495|16.03     |2022-08-17|London     |GB     |51.5     |-0.12    |21.84              |\n",
            "+------------+------------+------------------+-----------------------+-------+-----------+------+--------+------------------------------------+----------+--------+------------------------+---------+---------+----------+--------+------+----------+----------+-----------+-------+---------+---------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2021_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRgbFwU7mUnW",
        "outputId": "2a717944-19c0-445c-c36e-52f6b7b852c5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- franchise_id: string (nullable = true)\n",
            " |-- franchise_name: string (nullable = true)\n",
            " |-- restaurant_franchise_id: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- lng: string (nullable = true)\n",
            " |-- receipt_id: string (nullable = true)\n",
            " |-- total_cost: string (nullable = true)\n",
            " |-- discount: string (nullable = true)\n",
            " |-- date_time: string (nullable = true)\n",
            " |-- lat_round: double (nullable = true)\n",
            " |-- lng_round: double (nullable = true)\n",
            " |-- visit_date: date (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand\n",
        "\n",
        "\n",
        "receipt_2021_df = receipt_2021_df.withColumn(\"item_count\", (rand() * 10).cast(\"int\"))\n",
        "\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "receipt_2021_df = receipt_2021_df.withColumn(\n",
        "    \"order_type\",\n",
        "    when(col(\"item_count\").isNull() | (col(\"item_count\") <= 0), \"Erroneous data\")\n",
        "    .when(col(\"item_count\") <= 1, \"Tiny order\")\n",
        "    .when(col(\"item_count\") <= 3, \"Small order\")\n",
        "    .when(col(\"item_count\") <= 10, \"Medium order\")\n",
        "    .otherwise(\"Large order\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "tOmBbGMsmdET"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2021_df.select(\"receipt_id\", \"item_count\", \"order_type\").show(10, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtITUU79nBJy",
        "outputId": "6defe8e7-0051-4c04-cd65-6fca48ad1737"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------+----------+--------------+\n",
            "|receipt_id                          |item_count|order_type    |\n",
            "+------------------------------------+----------+--------------+\n",
            "|56df62bf-f7e7-47ff-8800-475bf46262cf|5         |Medium order  |\n",
            "|f3ed7e84-f3c7-46e7-b855-f6def62911bb|4         |Medium order  |\n",
            "|4cbfe14a-77ab-489e-aeb8-192931ad493a|7         |Medium order  |\n",
            "|397c3559-92fc-4f4d-9bf7-3ad47cb51620|0         |Erroneous data|\n",
            "|10ef1be3-83d3-47db-a7d0-de7d71924f91|5         |Medium order  |\n",
            "|140cd725-f63b-44a0-933e-26f18bc01af6|4         |Medium order  |\n",
            "|9cef05e6-f5c7-4a9e-8866-97b8dc17fca1|6         |Medium order  |\n",
            "|a49edfd8-a859-471a-886a-79ac5e404202|7         |Medium order  |\n",
            "|b7076235-0259-49ab-8663-b1368d746555|6         |Medium order  |\n",
            "|eeb91a45-9008-4dda-97a3-977a8ab1ceb5|9         |Medium order  |\n",
            "+------------------------------------+----------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2021_df.groupBy(\"order_type\").count().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCWLpYYLnM_x",
        "outputId": "531b7d1d-d6b2-46ea-cdf0-85a5d515f603"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------+\n",
            "|    order_type| count|\n",
            "+--------------+------+\n",
            "|Erroneous data|126728|\n",
            "|  Medium order|761890|\n",
            "|   Small order|253951|\n",
            "|    Tiny order|126771|\n",
            "+--------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "receipt_2021_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"/content/output/receipt_2021_enriched\")\n"
      ],
      "metadata": {
        "id": "uFI35kUSnPin"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aocQ7I1CneGg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}